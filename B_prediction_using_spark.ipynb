{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError:\n",
    "    print(\"sc not defined\")\n",
    "\n",
    "config = SparkConf().setMaster(\"local[*]\").setAppName(\"ClassifyUrl\")    \n",
    "sc = SparkContext(conf=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local\") \\\n",
    "                    .appName(\"Classify Urls\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'bigdata/train.csv'\n",
    "html_csv = 'bigdata/train/html_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = spark.read.csv(train_csv, \n",
    "                       header=True,\n",
    "                      inferSchema=True)\n",
    "\n",
    "# Analyze Data types in dataset\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Records in Training Dataset :', train.count())\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() gives Ugly Output :(\n",
    "# Prefer show() over head()\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns do we have in train and what are their names?\n",
    "print('No. of cols in train dataset : ', len(train.columns))\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to get the summary statistics (mean, standard deviance, min ,max , count) of numerical columns in a DataFrame?\n",
    "train.describe().show()\n",
    "\n",
    "'''\n",
    "Observation:\n",
    "As we can see that, describe operation is working for String type column but the output for mean, stddev are null and min & max values are calculated based on ASCII value of categories.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# How to select column(s) from the DataFrame?\n",
    "train.select('Webpage_id','Domain','Tag').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# How to find the number of distinct Domain and Tags (Target-Classes) in train files?\n",
    "train.select('Domain').distinct().count(), train.select('Tag').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null values in \n",
    "print('Count of Missing values in Train Dataset :\\n')\n",
    "print('Domain :', train.filter(train.Domain.isNull()).count())\n",
    "print('Url :', train.filter(train.Url.isNull()).count())\n",
    "print('Tag :', train.filter(train.Tag.isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to drop the all rows with null value?\n",
    "train.dropna().count() # Count of rows in newly returned non-null dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to fill the null values in Domain column of DataFrame with, some constant value, say, 'www.missing.in'?\n",
    "missing_domain = 'www.missing.in'\n",
    "train.fillna(missing_domain, 'Domain').count() # Count of rows in newly returned non-null dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create a sample DataFrame from the base DataFrame?\n",
    "train.sample(False, # withReplacement=False\n",
    "             0.0001, # fraction = x percecntage that we want to pick\n",
    "             42 # seed to reproduce the result\n",
    "            ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the number of rows we have per Domain?\n",
    "from pyspark.sql.functions import col\n",
    "train.groupBy('Domain') \\\n",
    "    .count() \\\n",
    "    .filter(\"`count` > 225\") \\\n",
    "    .sort(col('count').desc()) \\\n",
    "    .show(10) # Show Count of Top 10\n",
    "\n",
    "# Or like below:\n",
    "from pyspark.sql.functions import desc\n",
    "train.groupBy('Domain') \\\n",
    "    .count() \\\n",
    "    .filter(\"`count` > 225\") \\\n",
    "    .sort(desc('count')) \\\n",
    "    .show(10) # Show Count of Top 10\n",
    "\n",
    "# Or like below:\n",
    "from pyspark.sql.functions import desc\n",
    "train.groupBy('Domain') \\\n",
    "    .count() \\\n",
    "    .filter(\"`count` > 225\") \\\n",
    "    .orderBy('count', ascending=False) \\\n",
    "    .show(10) # Show Count of Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Wall time: 2.13s - 2.39s\n",
    "\n",
    "# OBJECTIVE : Get just the domain from URLs\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import tldextract\n",
    "\n",
    "def extract_domain(url):\n",
    "    return tldextract.extract(url).domain\n",
    "\n",
    "extract_domain_udf = udf(extract_domain, StringType())\n",
    "# extract_domain_udf = udf(lambda url : tldextract.extract(url).domain, StringType())\n",
    "\n",
    "train = train.withColumn('Domain', extract_domain_udf(train.Domain))\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # For Scraping HTML page\n",
    "from bs4.element import Comment\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective : Extract text from title tag of HTML source of web-page\n",
    "def extract_title(page):\n",
    "    if (page == None): \n",
    "        return None\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    title_tag = soup.find('title')\n",
    "    if (title_tag == None):\n",
    "        title = None\n",
    "    else:\n",
    "        title = title_tag.text.strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  OBJECTIVE: Functions to parse HTML content and extract text that matters.\n",
    "def extract_body(page):\n",
    "    if (page == None): \n",
    "        return None\n",
    "    soup = BeautifulSoup(page, 'html.parser', from_encoding=\"utf-8\")\n",
    "    body_tag = soup.find('body')\n",
    "    if (body_tag == None):\n",
    "        body = page \n",
    "    else:\n",
    "        body = body_tag # What should be returned here? How to stringify this for further  procecssing?\n",
    "    return body\n",
    "\n",
    "def is_visible_content(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def remove_extra_spaces(str):\n",
    "    return u\" \".join(str.split())\n",
    "\n",
    "def extract_text(page):\n",
    "    if (page == None): \n",
    "        return None\n",
    "    soup = BeautifulSoup(page, 'html.parser') #, from_encoding=\"utf-8\"\n",
    "    texts = soup.findAll(text=True) # Extracts text from all HTML Markups, incl nested ones\n",
    "    visible_texts = filter(is_visible_content, texts)\n",
    "    # The u-prefix u\" \".join() indicates Unicode and has been in python since v2.0\n",
    "    # Ref. Read: https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/\n",
    "    text = u\" \".join(remove_extra_spaces(t.strip()) for t in visible_texts)\n",
    "    text = text.replace(',','')\n",
    "    text = text.replace('|','')\n",
    "    text = re.sub(r'\\s\\s+',' ',text).strip()\n",
    "    return text.encode('utf-8',errors='ignore').decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.get(\"spark\", \"spark_parser_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# OBJECTIVE : Read html_data.csv\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import lit # lit for literals\n",
    "\n",
    "extract_text_udf = udf(extract_text, StringType())\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"Webpage_id\", IntegerType()),\n",
    "    StructField(\"Html\", StringType())\n",
    "])\n",
    "\n",
    "html_df = spark.read.csv(html_csv, \n",
    "                         header=True, \n",
    "                         multiLine=True, \n",
    "                         ignoreLeadingWhiteSpace=True, \n",
    "                         ignoreTrailingWhiteSpace=True, \n",
    "                         encoding=\"UTF-8\",\n",
    "                         sep=',',\n",
    "                         quote='\"', \n",
    "                         escape='\"',\n",
    "                         maxColumns=2,\n",
    "#                          mode='spark_parser_mode',\n",
    "#                          schema=schema)\n",
    "                         inferSchema=True)\n",
    "'''\n",
    "html_df = spark.read.format('csv') \\\n",
    "                    .option('header',True) \\\n",
    "                    .option('ignoreLeadingWhiteSpace',True) \\\n",
    "                    .option('ignoreTrailingWhiteSpace',True) \\\n",
    "                    .option('inferSchema',True) \\\n",
    "                    .option('maxColumns',2) \\\n",
    "                    .load(html_csv)\n",
    "'''\n",
    "# Analyze Data types in dataset\n",
    "html_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Adding a constant column \n",
    "html_df = html_df.withColumn('Title',lit(''))\n",
    "html_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 1h 10min 6s\n",
    "\n",
    "# OBJECTIVE : From html_data.csv loaded in df, extract title and text from html-page, and add the them to train.csv as new columns\n",
    "\n",
    "# Transforming an existing column\n",
    "html_df = html_df.withColumn('Html',extract_text_udf(html_df.Html))\n",
    "html_df = html_df.withColumnRenamed('Html','Html2Text')\n",
    "html_df.write.csv('bigdata/train/sparkoutput', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
