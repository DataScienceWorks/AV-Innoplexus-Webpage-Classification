{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Required Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Required Functions\n",
    "def getWordsFromURL(url):\n",
    "    return re.compile(r'[\\:/?=\\-&]+',re.UNICODE).split(url)\n",
    "def purity_score(clusters, classes):\n",
    "    \"\"\"\n",
    "    Calculate the purity score for the given cluster assignments and ground truth classes\n",
    "    \n",
    "    :param clusters: the cluster assignments array\n",
    "    :type clusters: numpy.array\n",
    "    \n",
    "    :param classes: the ground truth classes\n",
    "    :type classes: numpy.array\n",
    "    \n",
    "    :returns: the purity score\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.c_[(clusters,classes)]\n",
    "\n",
    "    n_accurate = 0.\n",
    "\n",
    "    for j in np.unique(A[:,0]):\n",
    "        z = A[A[:,0] == j, 1]\n",
    "        x = np.argmax(np.bincount(z))\n",
    "        n_accurate += len(z[z == x])\n",
    "\n",
    "    return n_accurate / A.shape[0]\n",
    "#did not use below two funtions due to loading and computiong issues with html_data size\n",
    "def pre_processing(html):\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "        # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "    if soup:\n",
    "        text1 = soup.get_text()\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text1.splitlines())\n",
    "        lines1= (line.replace('\\n','') for line in lines)\n",
    "        lines2= (line.replace('\\t','') for line in lines)\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines2 for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "        return clean_text(text)\n",
    "    else:\n",
    "        return 'No_data'\n",
    "def clean_text(text):\n",
    "    result = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", result).split())\n",
    "    #We're returning the tweet which is cleaned(after replacin' the above pattern to null which means deleting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53447, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading, preprocessing of data sets\n",
    "train=pd.read_csv('C:\\\\Users\\\\Ashok Chava\\\\Documents\\\\Kaggle\\\\AnalyticsVidhya\\\\train\\\\train.csv')\n",
    "train.head()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage_id</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Url</th>\n",
       "      <th>Tag</th>\n",
       "      <th>url_split</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/marketing/tecfider...</td>\n",
       "      <td>4</td>\n",
       "      <td>[http, www.fiercepharma.com, marketing, tecfid...</td>\n",
       "      <td>marketing tecfidera gilenya and aubagio s 3 wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/pharma/novo-equipp...</td>\n",
       "      <td>4</td>\n",
       "      <td>[http, www.fiercepharma.com, pharma, novo, equ...</td>\n",
       "      <td>pharma novo equipped to weather storm u s diab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/pharma/another-exe...</td>\n",
       "      <td>4</td>\n",
       "      <td>[http, www.fiercepharma.com, pharma, another, ...</td>\n",
       "      <td>pharma another exec departs troubled endo and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/pharma/teva-buy-bi...</td>\n",
       "      <td>4</td>\n",
       "      <td>[http, www.fiercepharma.com, pharma, teva, buy...</td>\n",
       "      <td>pharma teva buy biosim specialist celltrion it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/marketing/actress-...</td>\n",
       "      <td>4</td>\n",
       "      <td>[http, www.fiercepharma.com, marketing, actres...</td>\n",
       "      <td>marketing actress marissa tomei partners aller...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Webpage_id                Domain  \\\n",
       "0           1  www.fiercepharma.com   \n",
       "1           2  www.fiercepharma.com   \n",
       "2           3  www.fiercepharma.com   \n",
       "3           4  www.fiercepharma.com   \n",
       "4           5  www.fiercepharma.com   \n",
       "\n",
       "                                                 Url  Tag  \\\n",
       "0  http://www.fiercepharma.com/marketing/tecfider...    4   \n",
       "1  http://www.fiercepharma.com/pharma/novo-equipp...    4   \n",
       "2  http://www.fiercepharma.com/pharma/another-exe...    4   \n",
       "3  http://www.fiercepharma.com/pharma/teva-buy-bi...    4   \n",
       "4  http://www.fiercepharma.com/marketing/actress-...    4   \n",
       "\n",
       "                                           url_split  \\\n",
       "0  [http, www.fiercepharma.com, marketing, tecfid...   \n",
       "1  [http, www.fiercepharma.com, pharma, novo, equ...   \n",
       "2  [http, www.fiercepharma.com, pharma, another, ...   \n",
       "3  [http, www.fiercepharma.com, pharma, teva, buy...   \n",
       "4  [http, www.fiercepharma.com, marketing, actres...   \n",
       "\n",
       "                                              vector  \n",
       "0  marketing tecfidera gilenya and aubagio s 3 wa...  \n",
       "1  pharma novo equipped to weather storm u s diab...  \n",
       "2  pharma another exec departs troubled endo and ...  \n",
       "3  pharma teva buy biosim specialist celltrion it...  \n",
       "4  marketing actress marissa tomei partners aller...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading, preprocessing of data sets\n",
    "train['url_split']=train['Url'].apply(getWordsFromURL)\n",
    "list1=train['url_split'].tolist()\n",
    "list2=[i[2:] for i in list1]\n",
    "list3=[' '.join(i) for i in list2]\n",
    "train['vector']=list3\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage_id</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Url</th>\n",
       "      <th>url_split</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>isrctn.com</td>\n",
       "      <td>http://www.isrctn.com/ISRCTN57801413</td>\n",
       "      <td>[http, www.isrctn.com, ISRCTN57801413]</td>\n",
       "      <td>ISRCTN57801413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>www.clinicaltrialsregister.eu</td>\n",
       "      <td>https://www.clinicaltrialsregister.eu/ctr-sear...</td>\n",
       "      <td>[https, www.clinicaltrialsregister.eu, ctr, se...</td>\n",
       "      <td>ctr search trial 2006 006214 16 GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>www.clinicaltrialsregister.eu</td>\n",
       "      <td>https://www.clinicaltrialsregister.eu/ctr-sear...</td>\n",
       "      <td>[https, www.clinicaltrialsregister.eu, ctr, se...</td>\n",
       "      <td>ctr search trial 2006 004265 34 LT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>www.clinicaltrialsregister.eu</td>\n",
       "      <td>https://www.clinicaltrialsregister.eu/ctr-sear...</td>\n",
       "      <td>[https, www.clinicaltrialsregister.eu, ctr, se...</td>\n",
       "      <td>ctr search trial 2010 022183 12 IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>www.clinicaltrialsregister.eu</td>\n",
       "      <td>https://www.clinicaltrialsregister.eu/ctr-sear...</td>\n",
       "      <td>[https, www.clinicaltrialsregister.eu, ctr, se...</td>\n",
       "      <td>ctr search trial 2010 021349 36 NL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Webpage_id                         Domain  \\\n",
       "0          31                     isrctn.com   \n",
       "1          32  www.clinicaltrialsregister.eu   \n",
       "2          33  www.clinicaltrialsregister.eu   \n",
       "3          34  www.clinicaltrialsregister.eu   \n",
       "4          35  www.clinicaltrialsregister.eu   \n",
       "\n",
       "                                                 Url  \\\n",
       "0               http://www.isrctn.com/ISRCTN57801413   \n",
       "1  https://www.clinicaltrialsregister.eu/ctr-sear...   \n",
       "2  https://www.clinicaltrialsregister.eu/ctr-sear...   \n",
       "3  https://www.clinicaltrialsregister.eu/ctr-sear...   \n",
       "4  https://www.clinicaltrialsregister.eu/ctr-sear...   \n",
       "\n",
       "                                           url_split  \\\n",
       "0             [http, www.isrctn.com, ISRCTN57801413]   \n",
       "1  [https, www.clinicaltrialsregister.eu, ctr, se...   \n",
       "2  [https, www.clinicaltrialsregister.eu, ctr, se...   \n",
       "3  [https, www.clinicaltrialsregister.eu, ctr, se...   \n",
       "4  [https, www.clinicaltrialsregister.eu, ctr, se...   \n",
       "\n",
       "                               vector  \n",
       "0                      ISRCTN57801413  \n",
       "1  ctr search trial 2006 006214 16 GB  \n",
       "2  ctr search trial 2006 004265 34 LT  \n",
       "3  ctr search trial 2010 022183 12 IT  \n",
       "4  ctr search trial 2010 021349 36 NL  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading, preprocessing of data sets\n",
    "test=pd.read_csv('C:\\\\Users\\\\Ashok Chava\\\\Documents\\\\Kaggle\\\\AnalyticsVidhya\\\\test_nvPHrOx.csv')\n",
    "test['url_split']=test['Url'].apply(getWordsFromURL)\n",
    "list1_t=test['url_split'].tolist()\n",
    "list2_t=[i[2:] for i in list1_t]\n",
    "list3_t=[' '.join(i) for i in list2_t]\n",
    "test['vector']=list3_t\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading, preprocessing of data sets\n",
    "train['Tag']=train['Tag'].astype('category')\n",
    "train['Tag']=train['Tag'].cat.codes\n",
    "y_train=train['Tag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classification models\n",
    "vectorizer = CountVectorizer()\n",
    "x_train=vectorizer.fit_transform(train['vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9064306696353397\n"
     ]
    }
   ],
   "source": [
    "#classification models\n",
    "clf = MultinomialNB(alpha=1,fit_prior=True,class_prior=None)\n",
    "clf.fit(x_train, y_train)\n",
    "x_train_p=clf.predict(x_train)\n",
    "print(purity_score(x_train_p,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=vectorizer.transform(test['vector'])\n",
    "x_test_p=clf.predict(x_test)\n",
    "df_t = pd.DataFrame(x_test_p)\n",
    "df_t.to_csv('15th_in.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0 - clinicalTrials\n",
    "#1 - conferences\n",
    "#2 - forum\n",
    "#3 - guidelines\n",
    "#4 - news\n",
    "#5 - others\n",
    "#6 - profile\n",
    "#7 - publication\n",
    "#8 - thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tested below models too\n",
    "#clf=MLPClassifier(validation_fraction=0.2,verbose=True)\n",
    "#clf.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
